Movie Rating Prediction Model Summary
1. Objective
 I use a neural network to predict movie ratings and improve model performance through hyperparameter tuning.

2. Data Processing
Dataset Splitting
 (80% training set, 10% validation set, 10% test set.)
Data Normalization： Using StandardScaler to standardize all features for stable training.

3. Model Architecture
Input Layer 20 input features.
Hidden Layer： Uses ReLU activation and Dropout to prevent overfitting.
Output Layer： Predicts movie ratings.
4. Hyperparameter Tuning - Optuna
 optimize the below parameters:
Hidden Layer Neurons： Choosing the best values between 32 and 256.
Dropout Rate：0.1 ~ 0.5
 
Batch Size：{32, 64, 128}
 
Best Hyperparameters：

   {'hidden_dim1': 128,
    'hidden_dim2': 64,
    'dropout_rate': 0.3,
    'batch_size': 64}


5. Training the Model

 Using  hyperparameters, trained for 20 epochs with Adam optimizer (lr=0.001) and MSE loss function.)

6. Results
MSE: 0.018532
(*Final test MSE: 0.018532*)

Analysis： Hyperparameter tuning improved generalization and low error, and the model performed well.
7. Improvements
More Advanced Models



8. Conclusion

 This experiment successfully trained a neural network for movie rating prediction and improved performance through hyperparameter tuning. Further improvements like early stopping and adaptive learning rates can be explored.





{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6YxUC3pWv25-",
        "outputId": "576f1bf9-b086-4c34-ab17-3541fec89fbd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Collecting optuna\n",
            "  Downloading optuna-4.2.1-py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (1.26.4)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2024.10.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Collecting alembic>=1.5.0 (from optuna)\n",
            "  Downloading alembic-1.15.1-py3-none-any.whl.metadata (7.2 kB)\n",
            "Collecting colorlog (from optuna)\n",
            "  Downloading colorlog-6.9.0-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from optuna) (24.2)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.11/dist-packages (from optuna) (2.0.39)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from optuna) (4.67.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from optuna) (6.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.14.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.5.0)\n",
            "Collecting Mako (from alembic>=1.5.0->optuna)\n",
            "  Downloading Mako-1.3.9-py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy>=1.4.2->optuna) (3.1.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m95.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m74.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m42.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m53.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading optuna-4.2.1-py3-none-any.whl (383 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m383.6/383.6 kB\u001b[0m \u001b[31m22.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading alembic-1.15.1-py3-none-any.whl (231 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m231.8/231.8 kB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorlog-6.9.0-py3-none-any.whl (11 kB)\n",
            "Downloading Mako-1.3.9-py3-none-any.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.5/78.5 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, Mako, colorlog, nvidia-cusparse-cu12, nvidia-cudnn-cu12, alembic, optuna, nvidia-cusolver-cu12\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed Mako-1.3.9 alembic-1.15.1 colorlog-6.9.0 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 optuna-4.2.1\n"
          ]
        }
      ],
      "source": [
        "!pip install torch optuna pandas numpy scikit-learn\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "print(torch.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GR9BCoo3v9xW",
        "outputId": "d223f50c-4a64-49c1-a804-f3ad1ae3ba58"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.6.0+cu124\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.utils.data as data\n",
        "import optuna\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "\n",
        "X = np.random.rand(1000, 20)\n",
        "y = np.random.rand(1000)\n",
        "\n",
        "\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
        "\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_val = scaler.transform(X_val)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "\n",
        "class MovieRatingDataset(data.Dataset):\n",
        "    def __init__(self, X, y):\n",
        "        self.X = torch.tensor(X, dtype=torch.float32)\n",
        "        self.y = torch.tensor(y, dtype=torch.float32)\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "    def __getitem__(self, idx):\n",
        "        return self.X[idx], self.y[idx]\n",
        "\n",
        "\n",
        "class MovieRatingNN(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim1, hidden_dim2, dropout_rate):\n",
        "        super(MovieRatingNN, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_dim, hidden_dim1)\n",
        "        self.fc2 = nn.Linear(hidden_dim1, hidden_dim2)\n",
        "        self.fc3 = nn.Linear(hidden_dim2, 1)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.dropout = nn.Dropout(dropout_rate)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.relu(self.fc1(x))\n",
        "        x = self.dropout(x)\n",
        "        x = self.relu(self.fc2(x))\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc3(x)\n",
        "        return x.squeeze()\n",
        "\n",
        "\n",
        "X_train_small, _, y_train_small, _ = train_test_split(X_train, y_train, test_size=0.5, random_state=42)\n",
        "\n",
        "\n",
        "def objective(trial):\n",
        "    hidden_dim1 = trial.suggest_int('hidden_dim1', 32, 256)\n",
        "    hidden_dim2 = trial.suggest_int('hidden_dim2', 16, 128)\n",
        "    dropout_rate = trial.suggest_float('dropout_rate', 0.1, 0.5)\n",
        "    batch_size = trial.suggest_categorical('batch_size', [32, 64, 128])\n",
        "\n",
        "    model = MovieRatingNN(input_dim=X_train.shape[1], hidden_dim1=hidden_dim1, hidden_dim2=hidden_dim2, dropout_rate=dropout_rate)\n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "    criterion = nn.MSELoss()\n",
        "\n",
        "    train_loader = data.DataLoader(MovieRatingDataset(X_train_small, y_train_small), batch_size=batch_size, shuffle=True)\n",
        "    val_loader = data.DataLoader(MovieRatingDataset(X_val, y_val), batch_size=batch_size, shuffle=False)\n",
        "\n",
        "\n",
        "    for epoch in range(10):\n",
        "        model.train()\n",
        "        for batch_X, batch_y in train_loader:\n",
        "            optimizer.zero_grad()\n",
        "            output = model(batch_X)\n",
        "            loss = criterion(output, batch_y)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "\n",
        "    model.eval()\n",
        "    val_loss = 0\n",
        "    with torch.no_grad():\n",
        "        for batch_X, batch_y in val_loader:\n",
        "            output = model(batch_X)\n",
        "            val_loss += criterion(output, batch_y).item()\n",
        "    return val_loss / len(val_loader)\n",
        "\n",
        "\n",
        "study = optuna.create_study(direction='minimize')\n",
        "study.optimize(objective, n_trials=20)\n",
        "best_params = study.best_params\n",
        "\n",
        "\n",
        "hidden_dim1 = best_params['hidden_dim1']\n",
        "hidden_dim2 = best_params['hidden_dim2']\n",
        "dropout_rate = best_params['dropout_rate']\n",
        "batch_size = best_params['batch_size']\n",
        "\n",
        "\n",
        "final_model = MovieRatingNN(input_dim=X_train.shape[1], hidden_dim1=hidden_dim1, hidden_dim2=hidden_dim2, dropout_rate=dropout_rate)\n",
        "optimizer = optim.Adam(final_model.parameters(), lr=0.001)\n",
        "criterion = nn.MSELoss()\n",
        "\n",
        "train_loader = data.DataLoader(MovieRatingDataset(X_train, y_train), batch_size=batch_size, shuffle=True)\n",
        "test_loader = data.DataLoader(MovieRatingDataset(X_test, y_test), batch_size=batch_size, shuffle=False)\n",
        "\n",
        "\n",
        "for epoch in range(20):\n",
        "    final_model.train()\n",
        "    for batch_X, batch_y in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        output = final_model(batch_X)\n",
        "        loss = criterion(output, batch_y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "\n",
        "final_model.eval()\n",
        "test_loss = 0\n",
        "num_samples = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch_X, batch_y in test_loader:\n",
        "        output = final_model(batch_X)\n",
        "        loss = criterion(output, batch_y).item() * batch_X.size(0)\n",
        "        test_loss += loss\n",
        "        num_samples += batch_X.size(0)\n",
        "\n",
        "final_mse = test_loss / num_samples\n",
        "print(f\"最终测试集 MSE: {final_mse:.6f}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LA_cpFhEwqR2",
        "outputId": "e0d50cb3-9e2b-4606-883c-1399e454d83d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-03-14 22:54:15,933] A new study created in memory with name: no-name-b6bafbfe-f3f7-413a-b1a5-0cb4f4b74b2b\n",
            "[I 2025-03-14 22:54:16,420] Trial 0 finished with value: 0.09048150293529034 and parameters: {'hidden_dim1': 172, 'hidden_dim2': 116, 'dropout_rate': 0.17771551321215578, 'batch_size': 32}. Best is trial 0 with value: 0.09048150293529034.\n",
            "[I 2025-03-14 22:54:16,767] Trial 1 finished with value: 0.09573974832892418 and parameters: {'hidden_dim1': 136, 'hidden_dim2': 71, 'dropout_rate': 0.44411384195263304, 'batch_size': 64}. Best is trial 0 with value: 0.09048150293529034.\n",
            "[I 2025-03-14 22:54:16,946] Trial 2 finished with value: 0.09096202254295349 and parameters: {'hidden_dim1': 47, 'hidden_dim2': 44, 'dropout_rate': 0.40293061354778914, 'batch_size': 128}. Best is trial 0 with value: 0.09048150293529034.\n",
            "[I 2025-03-14 22:54:17,212] Trial 3 finished with value: 0.08508091792464256 and parameters: {'hidden_dim1': 115, 'hidden_dim2': 97, 'dropout_rate': 0.2780946996855854, 'batch_size': 64}. Best is trial 3 with value: 0.08508091792464256.\n",
            "[I 2025-03-14 22:54:17,515] Trial 4 finished with value: 0.09261326119303703 and parameters: {'hidden_dim1': 128, 'hidden_dim2': 102, 'dropout_rate': 0.10261152525347801, 'batch_size': 64}. Best is trial 3 with value: 0.08508091792464256.\n",
            "[I 2025-03-14 22:54:17,730] Trial 5 finished with value: 0.09685198962688446 and parameters: {'hidden_dim1': 184, 'hidden_dim2': 113, 'dropout_rate': 0.15691390597224011, 'batch_size': 128}. Best is trial 3 with value: 0.08508091792464256.\n",
            "[I 2025-03-14 22:54:17,946] Trial 6 finished with value: 0.08773289620876312 and parameters: {'hidden_dim1': 161, 'hidden_dim2': 77, 'dropout_rate': 0.4282651765933231, 'batch_size': 128}. Best is trial 3 with value: 0.08508091792464256.\n",
            "[I 2025-03-14 22:54:18,264] Trial 7 finished with value: 0.09332223050296307 and parameters: {'hidden_dim1': 159, 'hidden_dim2': 24, 'dropout_rate': 0.36857013359525237, 'batch_size': 32}. Best is trial 3 with value: 0.08508091792464256.\n",
            "[I 2025-03-14 22:54:18,605] Trial 8 finished with value: 0.09783674031496048 and parameters: {'hidden_dim1': 144, 'hidden_dim2': 105, 'dropout_rate': 0.17789156272732246, 'batch_size': 32}. Best is trial 3 with value: 0.08508091792464256.\n",
            "[I 2025-03-14 22:54:18,853] Trial 9 finished with value: 0.09280706942081451 and parameters: {'hidden_dim1': 194, 'hidden_dim2': 120, 'dropout_rate': 0.32636042007880917, 'batch_size': 64}. Best is trial 3 with value: 0.08508091792464256.\n",
            "[I 2025-03-14 22:54:19,070] Trial 10 finished with value: 0.08589722216129303 and parameters: {'hidden_dim1': 79, 'hidden_dim2': 82, 'dropout_rate': 0.2510764283472363, 'batch_size': 64}. Best is trial 3 with value: 0.08508091792464256.\n",
            "[I 2025-03-14 22:54:19,265] Trial 11 finished with value: 0.09077129885554314 and parameters: {'hidden_dim1': 79, 'hidden_dim2': 77, 'dropout_rate': 0.2594224945775037, 'batch_size': 64}. Best is trial 3 with value: 0.08508091792464256.\n",
            "[I 2025-03-14 22:54:19,480] Trial 12 finished with value: 0.080724086612463 and parameters: {'hidden_dim1': 239, 'hidden_dim2': 89, 'dropout_rate': 0.26471551381771796, 'batch_size': 64}. Best is trial 12 with value: 0.080724086612463.\n",
            "[I 2025-03-14 22:54:19,687] Trial 13 finished with value: 0.0883742980659008 and parameters: {'hidden_dim1': 241, 'hidden_dim2': 92, 'dropout_rate': 0.281329046552923, 'batch_size': 64}. Best is trial 12 with value: 0.080724086612463.\n",
            "[I 2025-03-14 22:54:19,903] Trial 14 finished with value: 0.0876866914331913 and parameters: {'hidden_dim1': 247, 'hidden_dim2': 58, 'dropout_rate': 0.3330404490434346, 'batch_size': 64}. Best is trial 12 with value: 0.080724086612463.\n",
            "[I 2025-03-14 22:54:20,116] Trial 15 finished with value: 0.08768352121114731 and parameters: {'hidden_dim1': 221, 'hidden_dim2': 97, 'dropout_rate': 0.22154135682812984, 'batch_size': 64}. Best is trial 12 with value: 0.080724086612463.\n",
            "[I 2025-03-14 22:54:20,307] Trial 16 finished with value: 0.10136397555470467 and parameters: {'hidden_dim1': 104, 'hidden_dim2': 126, 'dropout_rate': 0.4869113490392438, 'batch_size': 64}. Best is trial 12 with value: 0.080724086612463.\n",
            "[I 2025-03-14 22:54:20,519] Trial 17 finished with value: 0.08735910803079605 and parameters: {'hidden_dim1': 214, 'hidden_dim2': 61, 'dropout_rate': 0.3073410195017198, 'batch_size': 64}. Best is trial 12 with value: 0.080724086612463.\n",
            "[I 2025-03-14 22:54:20,667] Trial 18 finished with value: 0.08638227730989456 and parameters: {'hidden_dim1': 111, 'hidden_dim2': 84, 'dropout_rate': 0.21920322761823618, 'batch_size': 128}. Best is trial 12 with value: 0.080724086612463.\n",
            "[I 2025-03-14 22:54:21,009] Trial 19 finished with value: 0.09242834337055683 and parameters: {'hidden_dim1': 44, 'hidden_dim2': 91, 'dropout_rate': 0.3707955399773489, 'batch_size': 32}. Best is trial 12 with value: 0.080724086612463.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "最终测试集 MSE: 0.069711\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hidden_dim1 = best_params['hidden_dim1']\n",
        "hidden_dim2 = best_params['hidden_dim2']\n",
        "dropout_rate = best_params['dropout_rate']\n",
        "batch_size = best_params['batch_size']\n"
      ],
      "metadata": {
        "id": "78euTwsv7cWI"
      },
      "execution_count": 26,
      "outputs": []
    }
  ]
}
